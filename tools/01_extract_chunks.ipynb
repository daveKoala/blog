{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5df8971a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /Users/davidclare/Projects/git-pages-blog/.venv/lib/python3.9/site-packages (25.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade pip\n",
    "\n",
    "%pip install -q -r ./requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d00e2a0",
   "metadata": {},
   "source": [
    "Extract and chunk from blog posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4d9f34c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import frontmatter, os, json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "21b407ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_chunks_from_markdown(md_path, normalize_chunk_text=lambda x: x):\n",
    "    \"\"\"\n",
    "    Extracts chunks from a Markdown file, splitting by headings and normalizing text.\n",
    "    Args:\n",
    "        md_path (str): Path to the Markdown file.\n",
    "        normalize_chunk_text (function): Function to normalize chunk text.\n",
    "    Returns:\n",
    "        list: A list of dictionaries, each containing the title, heading, chunk text, tags, category, and path.\n",
    "    \"\"\"\n",
    "    post = frontmatter.load(md_path)\n",
    "    title = post.get(\"title\", os.path.basename(md_path))\n",
    "    tags = post.get(\"tags\", [])\n",
    "    category = post.get(\"category\", \"\")\n",
    "    lines = post.content.splitlines()\n",
    "\n",
    "    chunks = []\n",
    "    current_chunk = []\n",
    "    current_heading = \"Introduction\"\n",
    "\n",
    "    for line in lines:\n",
    "        if line.startswith(\"##\"):\n",
    "            if current_chunk:\n",
    "                chunks.append(\n",
    "                    {\n",
    "                        \"title\": title,\n",
    "                        \"heading\": current_heading,\n",
    "                        \"chunk\": \"\\n\".join(current_chunk).strip(),\n",
    "                        \"tags\": tags,\n",
    "                        \"category\": category,\n",
    "                        \"path\": md_path,\n",
    "                    }\n",
    "                )\n",
    "                current_chunk = []\n",
    "            current_heading = line.strip(\"# \").strip()\n",
    "        else:\n",
    "            current_chunk.append(line)\n",
    "\n",
    "    # Final chunk\n",
    "    if current_chunk:\n",
    "        chunk_text = normalize_chunk_text(\"\\n\".join(current_chunk))\n",
    "        chunks.append(\n",
    "            {\n",
    "                \"title\": title,\n",
    "                \"heading\": current_heading,\n",
    "                \"chunk\":chunk_text,\n",
    "                # \"chunk\": \"\\n\".join(current_chunk).strip(),\n",
    "                \"tags\": tags,\n",
    "                \"category\": category,\n",
    "                \"path\": md_path,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0e7a25e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "def get_chunk_writer(filename):\n",
    "    f = open(filename, \"w\", encoding=\"utf-8\")  # or \"a\" for append mode\n",
    "\n",
    "    def write_chunk(chunk):\n",
    "        f.write(json.dumps(chunk) + \"\\n\")\n",
    "\n",
    "    return write_chunk, f.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4d8eb03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def normalize_chunk_text(text):\n",
    "    text = text.strip()\n",
    "    text = re.sub(r\"\\n{2,}\", \"\\n\\n\", text)  # collapse 3+ newlines to 2\n",
    "    text = re.sub(r\"[ \\t]+\", \" \", text)  # normalize whitespace\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f916f2f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: 2024-12-12-osx-tree.md\n",
      "Processing file: 2025-03-28-rules-vrs-reality.md\n",
      "Processing file: 2025-03-28-assertions-vs-validation.md\n",
      "Processing file: 2024-04-12-enhancing-focus-with-thematic-sprints-in-our-dynamic-development-team.md\n",
      "Processing file: __2010-02-05-post-quote.md\n",
      "Processing file: 2023-02-23-replacing-objectid-with-a-string.md\n",
      "Processing file: 2025-04-07-rag-at-scale-is-hard-what-startups-get-wrong.md\n",
      "Processing file: 2025-06-01-what-climbing-has-taught-me-about-dev-teams.md\n",
      "Processing file: __2010-03-07-post-link.md\n",
      "Processing file: 2025-04-23-postman-reusable-scripts.md\n",
      "Processing file: __2010-02-05-post-notice.md\n",
      "Processing file: 2025-04-02-lexicon.md\n",
      "Processing file: 2024-05-10-npm-install.md\n",
      "Processing file: 2024-01-06-azure-appinsights-with-nodejs-adding-operation-id-to-response.md\n",
      "Processing file: 2025-03-12-web-hygiene.md\n",
      "Processing file: 2023-10-17-postman-and-faker.md\n",
      "Processing file: 2024-11-24-azure-appinsights-query-logs.md\n",
      "Processing file: 2024-04-27-basic-patterns-for-99-of-development.md\n",
      "Processing file: 2025-03-12-validating-tls-versions.md\n",
      "Processing file: 2025-03-12-deterministic-randomness-shuffling-with-seeds.md\n",
      "Processing file: 2025-03-21-generative-ai-powerful-imitation-not-true-intelligence.md\n",
      "Processing file: 2023-08-24-development-questions.md\n",
      "Processing file: __2010-01-07-post-standard.md\n",
      "Processing file: 2023-11-04-google-email-address.md\n",
      "Processing file: 2025-03-31-power-of-10.md\n",
      "Processing file: 2023-10-05-try-catch.md\n",
      "Processing file: __2010-01-07-post-modified.md\n",
      "Processing file: 2024-05-08-npm-dependency-notation.md\n",
      "Processing file: __2019-04-18-welcome-to-jekyll.md\n",
      "Processing file: 2025-04-10-from_adding_machines_to_ambiguity.md\n",
      "Processing file: 2024-05-18-build-what-users-want.md\n",
      "Processing file: 2025-03-12-stand-ups.md\n",
      "Processing file: __2010-01-08-post-chat.md\n"
     ]
    }
   ],
   "source": [
    "write_chunk, close_writer = get_chunk_writer(\"chunks_raw.jsonl\")\n",
    "\n",
    "# all_chunks = []\n",
    "\n",
    "for file in os.listdir(\"../_posts\"):\n",
    "    if file.endswith(\".md\"):\n",
    "        full_path = os.path.join(\"../_posts\", file)\n",
    "        print(f\"Processing file: {file}\")\n",
    "        chunks = extract_chunks_from_markdown(full_path, normalize_chunk_text=normalize_chunk_text)\n",
    "        for chunk in chunks:\n",
    "            write_chunk(chunk)  # Write each chunk to the file\n",
    "        # all_chunks.extend(chunks)\n",
    "\n",
    "close_writer()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
